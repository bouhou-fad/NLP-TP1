{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"NLP-SPACY-AR.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"50643f65"},"source":["# NLP_TP1_SPACY_Arabic\n","\n","# DATA\n","# TEXTE ARABE"],"id":"50643f65"},{"cell_type":"code","metadata":{"id":"eb35167e"},"source":["import spacy\n","from spacy.lang.ar import *\n","\n","nlp = Arabic()\n","txt=nlp(\"\"\"ربما كانت أحد أهم التطورات التي قامت بها الرياضيات العربية التي بدأت في هذا الوقت بعمل الخوارزمي و هي بدايات الجبر، و من المهم فهم كيف كانت هذه الفكرة الجديدة مهمة، فقد كانت خطوة ثورية بعيدا عن المفهوم اليوناني للرياضيات التي هي في جوهرها هندسة، الجبر كان نظرية موحدة تتيح الأعداد الكسرية و الأعداد اللا كسرية، و قدم وسيلة للتنمية في هذا الموضوع مستقبلا. و جانب آخر مهم لإدخال أفكار الجبر و هو أنه سمح بتطبيق الرياضيات على نفسها بطريقة لم تحدث من قبل\"\"\")\n","\n"],"id":"eb35167e","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aa06a4df"},"source":["# TOKENAZITION\n"],"id":"aa06a4df"},{"cell_type":"code","metadata":{"scrolled":false,"id":"b7b84b03","outputId":"72b85568-f324-4ffa-dba2-11f4f2e6220d"},"source":["for tok in txt:\n","    print(tok.text)\n","    print(tok.pos_)\n","    print( tok.tag_)\n","    "],"id":"b7b84b03","execution_count":null,"outputs":[{"output_type":"stream","text":["ربما\n","\n","\n","كانت\n","\n","\n","أحد\n","\n","\n","أهم\n","\n","\n","التطورات\n","\n","\n","التي\n","\n","\n","قامت\n","\n","\n","بها\n","\n","\n","الرياضيات\n","\n","\n","العربية\n","\n","\n","التي\n","\n","\n","بدأت\n","\n","\n","في\n","\n","\n","هذا\n","\n","\n","الوقت\n","\n","\n","بعمل\n","\n","\n","الخوارزمي\n","\n","\n","و\n","\n","\n","هي\n","\n","\n","بدايات\n","\n","\n","الجبر\n","\n","\n","،\n","\n","\n","و\n","\n","\n","من\n","\n","\n","المهم\n","\n","\n","فهم\n","\n","\n","كيف\n","\n","\n","كانت\n","\n","\n","هذه\n","\n","\n","الفكرة\n","\n","\n","الجديدة\n","\n","\n","مهمة\n","\n","\n","،\n","\n","\n","فقد\n","\n","\n","كانت\n","\n","\n","خطوة\n","\n","\n","ثورية\n","\n","\n","بعيدا\n","\n","\n","عن\n","\n","\n","المفهوم\n","\n","\n","اليوناني\n","\n","\n","للرياضيات\n","\n","\n","التي\n","\n","\n","هي\n","\n","\n","في\n","\n","\n","جوهرها\n","\n","\n","هندسة\n","\n","\n","،\n","\n","\n","الجبر\n","\n","\n","كان\n","\n","\n","نظرية\n","\n","\n","موحدة\n","\n","\n","تتيح\n","\n","\n","الأعداد\n","\n","\n","الكسرية\n","\n","\n","و\n","\n","\n","الأعداد\n","\n","\n","اللا\n","\n","\n","كسرية\n","\n","\n","،\n","\n","\n","و\n","\n","\n","قدم\n","\n","\n","وسيلة\n","\n","\n","للتنمية\n","\n","\n","في\n","\n","\n","هذا\n","\n","\n","الموضوع\n","\n","\n","مستقبلا\n","\n","\n",".\n","\n","\n","و\n","\n","\n","جانب\n","\n","\n","آخر\n","\n","\n","مهم\n","\n","\n","لإدخال\n","\n","\n","أفكار\n","\n","\n","الجبر\n","\n","\n","و\n","\n","\n","هو\n","\n","\n","أنه\n","\n","\n","سمح\n","\n","\n","بتطبيق\n","\n","\n","الرياضيات\n","\n","\n","على\n","\n","\n","نفسها\n","\n","\n","بطريقة\n","\n","\n","لم\n","\n","\n","تحدث\n","\n","\n","من\n","\n","\n","قبل\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f00a7f33"},"source":["# LEMMATIZATION\n"],"id":"f00a7f33"},{"cell_type":"code","metadata":{"id":"dfd8c756","outputId":"bc92d65c-6cf7-4c28-b7b1-71a3d48568be"},"source":["for word in txt:\n","    print(word.text + ':' , word.lemma_ )    "],"id":"dfd8c756","execution_count":null,"outputs":[{"output_type":"stream","text":["ربما: \n","كانت: \n","أحد: \n","أهم: \n","التطورات: \n","التي: \n","قامت: \n","بها: \n","الرياضيات: \n","العربية: \n","التي: \n","بدأت: \n","في: \n","هذا: \n","الوقت: \n","بعمل: \n","الخوارزمي: \n","و: \n","هي: \n","بدايات: \n","الجبر: \n","،: \n","و: \n","من: \n","المهم: \n","فهم: \n","كيف: \n","كانت: \n","هذه: \n","الفكرة: \n","الجديدة: \n","مهمة: \n","،: \n","فقد: \n","كانت: \n","خطوة: \n","ثورية: \n","بعيدا: \n","عن: \n","المفهوم: \n","اليوناني: \n","للرياضيات: \n","التي: \n","هي: \n","في: \n","جوهرها: \n","هندسة: \n","،: \n","الجبر: \n","كان: \n","نظرية: \n","موحدة: \n","تتيح: \n","الأعداد: \n","الكسرية: \n","و: \n","الأعداد: \n","اللا: \n","كسرية: \n","،: \n","و: \n","قدم: \n","وسيلة: \n","للتنمية: \n","في: \n","هذا: \n","الموضوع: \n","مستقبلا: \n",".: \n","و: \n","جانب: \n","آخر: \n","مهم: \n","لإدخال: \n","أفكار: \n","الجبر: \n","و: \n","هو: \n","أنه: \n","سمح: \n","بتطبيق: \n","الرياضيات: \n","على: \n","نفسها: \n","بطريقة: \n","لم: \n","تحدث: \n","من: \n","قبل: \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7a9d40e6","outputId":"a69044dc-382f-441a-b70d-16af3af9da3e"},"source":["#sentence tokenization\n","for s in txt.sents:\n","    print(s)"],"id":"7a9d40e6","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-26-175bccbf33d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sentence tokenization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\anaconda\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."]}]},{"cell_type":"code","metadata":{"id":"92fb99a2","outputId":"f948ea1e-b4ef-4d83-f11a-e1f39f154243"},"source":["import spacy\n","from spacy.lang.en import *\n","\n","# Load English tokenizer, tagger, parser, NER and word vectors\n","nlp = English()\n","\n","# Create the pipeline 'sentencizer' component\n","#sbd = nlp.create_pipe('sentencizer')\n","\n","# Add the component to the pipeline\n","nlp.add_pipe(sbd)\n","\n","text = \"\"\"When learning data science, you shouldn't get discouraged!\n","Challenges and setbacks aren't failures, they're just part of the journey. You've got this!\"\"\"\n","\n","#  \"nlp\" Object is used to create documents with linguistic annotations.\n","doc = nlp(text)\n","\n","# create list of sentence tokens\n","sents_list = []\n","for sent in doc.sents:\n","    sents_list.append(sent.text)\n","print(sents_list)"],"id":"92fb99a2","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000027B876B5D00> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-31-c044990432dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Add the component to the pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msbd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m text = \"\"\"When learning data science, you shouldn't get discouraged!\n","\u001b[1;32mC:\\anaconda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[1;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mbad_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfactory_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE966\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbad_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mfactory_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponent_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.sentencizer.Sentencizer object at 0x0000027B876B5D00> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."]}]},{"cell_type":"code","metadata":{"id":"8ab864f6"},"source":[""],"id":"8ab864f6","execution_count":null,"outputs":[]}]}